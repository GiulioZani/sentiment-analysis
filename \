import torch
import torch.nn.functional as F


class SelfAttention(torch.nn.Module):
    def __init__(self):
        pass


class TrasformerBlock(torch.nn.Module):
    def __init__(self):
        pass


class Trasformer(torch.nn.Module):
    def __init__(self, embedding_dim, num_heads, num_tokens, depth, num_labels):
        
